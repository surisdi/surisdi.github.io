<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dídac Surís - Meta Superintelligence Labs</title>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-3N5K82WVJT"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-3N5K82WVJT');
    </script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #eee;
            background-color: #252a34;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }

        /* Navigation Tabs */
        .nav-tabs {
            position: sticky;
            top: 0;
            background-color: #1a1d24;
            z-index: 100;
            padding: 15px 0;
            margin-bottom: 30px;
            border-bottom: 2px solid #3a3f4a;
        }

        .nav-tabs ul {
            list-style: none;
            display: flex;
            justify-content: center;
            gap: 30px;
        }

        .nav-tabs a {
            color: #eee;
            text-decoration: none;
            font-size: 1.1em;
            padding: 8px 16px;
            border-radius: 4px;
            transition: background-color 0.3s;
            cursor: pointer;
        }

        .nav-tabs a:hover {
            background-color: #3a3f4a;
        }

        .nav-tabs a.active {
            background-color: #4a9eff;
        }

        /* Tab Content */
        .tab-content {
            display: block;
        }

        /* Header */
        .header {
            text-align: center;
            padding: 40px 0;
            margin-bottom: 40px;
        }

        .profile-img {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            margin-bottom: 20px;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #fff;
        }

        .header .subtitle {
            font-size: 1.2em;
            color: #aaa;
        }

        .social-links {
            margin-top: 20px;
        }

        .social-links a {
            color: #eee;
            margin: 0 10px;
            text-decoration: none;
            font-size: 0.95em;
        }

        .social-links a:hover {
            color: #4a9eff;
        }

        /* Sections */
        section {
            margin-bottom: 60px;
        }

        h2 {
            font-size: 2em;
            margin-bottom: 20px;
            color: #fff;
            border-bottom: 2px solid #4a9eff;
            padding-bottom: 10px;
        }

        p {
            margin-bottom: 15px;
        }

        a {
            color: #4a9eff;
        }

        a:hover {
            color: #7ab8ff;
        }

        /* Publications */
        :root {
            --publication-spacing: 0.3em;
        }

        .post-container {
            margin: 20px 0;
            border: 1px solid #3a3f4a;
            overflow: auto;
            font-size: 95%;
            padding: 20px;
            border-radius: 8px;
            background-color: #2a2f3a;
        }

        .post-content .paper-title {
            display: inline;
        }

        .post-content .title-line {
            display: block;
            margin-top: var(--publication-spacing);
        }

        .post-content .spacing-before {
            display: block;
        }

        .post-content .spacing-after {
            display: block;
        }

        .post-content p i {
            display: inline-block;
            padding-top: var(--publication-spacing);
        }

        .post-content p a[href*="toggleBibtex"] {
            display: inline-block;
            padding-top: var(--publication-spacing);
        }

        .post-thumb {
            float: left;
        }

        .post-thumb img {
            display: block;
        }

        .post-content {
            margin-left: 210px;
        }

        .icons {
            border-radius: 10%;
            width: 150px;
            height: 150px;
            object-fit: cover;
        }

        .newpaper {
            border-radius: 5px;
            background: #ff2e3c;
            padding: 3px 6px;
            font-weight: bold;
            font-family: Arial, Helvetica, sans-serif;
            font-size: 0.75em;
            margin-left: 5px;
        }

        div.noshow {
            display: none;
        }

        div.bibtex {
            margin-right: 0%;
            margin-top: 1.2em;
            margin-bottom: 1em;
            border: 1px solid #4a4a4a;
            padding: 0em 1em;
            background: #1a1d24;
            border-radius: 4px;
        }

        div.bibtex pre {
            font-size: 80%;
            overflow: auto;
            width: 100%;
            padding: 0em 0em;
            color: #ddd;
        }

        /* Resume */
        .resume-highlight {
            background-color: #2a2f3a;
            padding: 30px;
            border-radius: 8px;
            text-align: center;
            margin-bottom: 30px;
            border: 2px solid #4a9eff;
        }

        .resume-highlight a {
            display: inline-block;
            background-color: #4a9eff;
            color: #fff;
            padding: 15px 30px;
            text-decoration: none;
            border-radius: 6px;
            font-size: 1.2em;
            font-weight: bold;
            transition: background-color 0.3s;
        }

        .resume-highlight a:hover {
            background-color: #3a8eef;
        }

        .resume-section {
            margin-top: 30px;
        }

        .resume-section h3 {
            color: #4a9eff;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .resume-section ul {
            list-style-position: inside;
            margin-left: 20px;
        }

        .resume-section li {
            margin-bottom: 10px;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .nav-tabs ul {
                flex-direction: column;
                gap: 10px;
            }

            .post-thumb {
                float: none;
                margin-bottom: 15px;
            }

            .post-content {
                margin-left: 0;
            }

            .icons {
                width: 100%;
                height: auto;
                max-width: 150px;
            }
        }
    </style>
</head>
<body>
    <nav class="nav-tabs">
        <ul>
            <li><a href="#about" class="tab-link">About</a></li>
            <li><a href="#publications" class="tab-link">Publications</a></li>
            <li><a href="#resume" class="tab-link">Resume</a></li>
        </ul>
    </nav>

    <div class="container">
        <!-- ABOUT SECTION -->
        <div id="about" class="tab-content">
            <header class="header">
                <img src="/assets/images/BIO-PHOTO.png" alt="Dídac Surís" class="profile-img">
                <h1>Dídac Surís Coll-Vinent</h1>
                <p class="subtitle">Research Scientist at Meta Superintelligence Labs</p>
                <div class="social-links">
                    <a href="mailto:didac.suris@gmail.com">Email</a> |
                    <a href="https://scholar.google.com/citations?user=6tOiGLAAAAAJ" target="_blank">Google Scholar</a> |
                    <a href="https://twitter.com/surisdi" target="_blank">Twitter</a> |
                    <a href="https://www.linkedin.com/in/didacsuris" target="_blank">LinkedIn</a> |
                    <a href="https://www.instagram.com/didacsuris" target="_blank">Instagram</a>
                </div>
            </header>

            <section id="bio">
                <h2>About Me</h2>
                <p>
                    I am a Research Scientist at <a href="https://ai.meta.com">Meta Superintelligence Labs</a>. I obtained my PhD from <a href="https://www.cs.columbia.edu">Columbia University</a>, where I was a Microsoft PhD fellow and worked under the supervision of <a href="http://www.cs.columbia.edu/~vondrick/">Professor Carl Vondrick</a>.
                </p>
                <p>
                    My interests are multimodal machine learning, video representations and self-supervised learning, and in general all
                    the areas of artificial intelligence that involve using all the available information in an intelligent way.
                </p>
                <p>
                    Before moving to New York, I was a researcher at the
                    <a href="https://vectorinstitute.ai/">Vector Institute</a>, working in
                    <a href="https://www.cs.utoronto.ca/~fidler/">Professor Sanja Fidler's lab</a>. I was previously a visiting student at <a href="https://www.csail.mit.edu">CSAIL-MIT</a>, working in
                    <a href="http://web.mit.edu/torralba/www/">Professor Antonio Torralba's lab</a>, and I studied both the
                    undergrad and a Master's in telecommunications in the <a href="https://www.upc.edu/en?set_language=en">UPC</a>, in Barcelona.
                    I have also been lucky to work at Telefonica with <a href="https://joanserra.weebly.com">Joan Serrà</a>, at
                    Adobe with <a href="https://www.justinsalamon.com">Justin Salamon</a> and <a href="https://bryanrussell.org">Bryan Russell</a>, and at Meta (FAIR) with <a href="http://people.csail.mit.edu/yalesong/home/">Yale Song</a> and <a href="https://ltorresa.github.io/home.html">Lorenzo Torresani</a>.
                </p>
                <p>
                    In my free time, I like to play the classical guitar. Maybe (probably not) some day I'll upload some recording of me playing. Also, <a href="https://www.cs.columbia.edu/2022/phd-didac-suris/">I got interviewed</a> by the Columbia CS department about my experience as a PhD student.
                </p>
            </section>
        </div>

        <!-- PUBLICATIONS SECTION -->
        <div id="publications" class="tab-content">
            <section>
                <h2>Publications</h2>
                <p>My publications are also listed in my <a href="https://scholar.google.com/citations?user=6tOiGLAAAAAJ">Google Scholar profile</a>.</p>

                <div class="post-container" id="sam3-ref">
                    <div class="post-thumb">
                        <img class="icons" src="/assets/images/sam3.gif" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            Nicolas Carion,
                            Laura Gustafson,
                            Yuan-Ting Hu,
                            Shoubhik Debnath,
                            Ronghang Hu,
                            <b>Dídac Surís</b>,
                            Chaitanya Ryali,
                            Kalyan Vasudev Alwala,
                            Haitham Khedr,
                            Andrew Huang,
                            Jie Lei,
                            Tengyu Ma,
                            Baishan Guo,
                            Arpit Kalla,
                            Markus Marks,
                            Joseph Greer,
                            Meng Wang,
                            Peize Sun,
                            Roman Rädle,
                            Triantafyllos Afouras,
                            Effrosyni Mavroudi,
                            Katherine Xu,
                            Tsung-Han Wu,
                            Yu Zhou,
                            Liliane Momeni,
                            Rishi Hazra,
                            Shuangrui Ding,
                            Sagar Vaze,
                            Francois Porcher,
                            Feng Li,
                            Siyuan Li,
                            Aishwarya Kamath,
                            Ho Kei Cheng,
                            Piotr Dollár,
                            Nikhila Ravi,
                            Kate Saenko,
                            Pengchuan Zhang,
                            Christoph Feichtenhofer
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">SAM 3: Segment Anything with Concepts</b> <span class="newpaper">NEW!</span></span>
                            <i>arXiv preprint</i>, 2025.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Carion2024sam3')">[BibTeX]</a>
                            <a href="https://arxiv.org/abs/2511.16719" target="_blank">[PDF]</a>
                            <a href="https://ai.meta.com/sam3" target="_blank">[Website]</a>
                            <a href="https://aidemos.meta.com" target="_blank">[Demo]</a>
                            <a href="https://ai.meta.com/blog/segment-anything-model-3/" target="_blank">[Blog]</a>
                            <a href="https://github.com/facebookresearch/sam3" target="_blank">[Code]</a>
                        </p>
                        <div id="bib_Carion2024sam3" class="bibtex noshow">
                            <pre>@article{carion2025sam3,
    title={SAM 3: Segment Anything with Concepts},
    author={Nicolas Carion and Laura Gustafson and Yuan-Ting Hu and Shoubhik Debnath and Ronghang Hu and D\'idac Sur\'is and Chaitanya Ryali and Kalyan Vasudev Alwala and Haitham Khedr and Andrew Huang and Jie Lei and Tengyu Ma and Baishan Guo and Arpit Kalla and Markus Marks and Joseph Greer and Meng Wang and Peize Sun and Roman R{\"a}dle and Triantafyllos Afouras and Effrosyni Mavroudi and Katherine Xu and Tsung-Han Wu and Yu Zhou and Liliane Momeni and Rishi Hazra and Shuangrui Ding and Sagar Vaze and Francois Porcher and Feng Li and Siyuan Li and Aishwarya Kamath and Ho Kei Cheng and Piotr Doll{\'a}r and Nikhila Ravi and Kate Saenko and Pengchuan Zhang and Christoph Feichtenhofer},
    journal={arXiv preprint arXiv:2511.16719},
    year={2025}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="safari-ref">
                    <div class="post-thumb">
                        <img class="icons" src="/assets/images/safari.gif" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            Dante Francisco Wasmuht,
                            Otto Brookes,
                            Maximillian Schall,
                            Pablo Palencia,
                            Chris Beirne,
                            Tilo Burghardt,
                            Majid Mirmehdi,
                            Hjalmar Kühl,
                            Mimi Arandjelovic,
                            Sam Pottie,
                            Peter Bermant,
                            Brandon Asheim,
                            Yi Jin Toh,
                            Adam Elzinga,
                            Jason Holmberg,
                            Andrew Whitworth,
                            Eleanor Flatt,
                            Laura Gustafson,
                            Chaitanya Ryali,
                            Yuan-Ting Hu,
                            Baishan Guo,
                            Andrew Westbury,
                            Kate Saenko,
                            <b>Dídac Surís</b>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification</b> <span class="newpaper">NEW!</span></span>
                            <i>arXiv preprint</i>, 2025.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Wasmuht2024safari')">[BibTeX]</a>
                            <a href="https://arxiv.org/abs/2511.15622" target="_blank">[PDF]</a>
                            <a href="https://conservationxlabs.com/sa-fari" target="_blank">[Website]</a>
                        </p>
                        <div id="bib_Wasmuht2024safari" class="bibtex noshow">
                            <pre>@article{wasmuht2025safari,
    title={The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification},
    author={Dante Francisco Wasmuht and Otto Brookes and Maximillian Schall and Pablo Palencia and Chris Beirne and Tilo Burghardt and Majid Mirmehdi and Hjalmar K{\"u}hl and Mimi Arandjelovic and Sam Pottie and Peter Bermant and Brandon Asheim and Yi Jin Toh and Adam Elzinga and Jason Holmberg and Andrew Whitworth and Eleanor Flatt and Laura Gustafson and Chaitanya Ryali and Yuan-Ting Hu and Baishan Guo and Andrew Westbury and Kate Saenko and D\'idac Sur\'is},
    journal={arXiv preprint arXiv:2511.15622},
    year={2025}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="gestalt-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/gestalt.gif" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <a href="https://egeozguroglu.github.io/" target="_blank">Ege Ozguroglu</a>,
                            <a href="https://ruoshiliu.github.io/" target="_blank">Ruoshi Liu</a>,
                            <b>Dídac Surís</b>,
                            <a href="https://www.dianchen.io/" target="_blank">Dian Chen</a>,
                            <a href="https://www.achaldave.com/" target="_blank">Achal Dave</a>,
                            <a href="https://pvtokmakov.github.io/home/" target="_blank">Pavel Tokmakov</a>,
                            <a href="https://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">pix2gestalt: Amodal Segmentation by Synthesizing Wholes</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2024.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Ozguroglu2024pix2gestalt')">[BibTeX]</a>
                            <a href="https://arxiv.org/abs/2401.14398" target="_blank">[PDF]</a>
                            <a href="https://gestalt.cs.columbia.edu/">[Website]</a>
                        </p>
                        <div id="bib_Ozguroglu2024pix2gestalt" class="bibtex noshow">
                            <pre>@article{ozguroglu2024pix2gestalt,
    title={pix2gestalt: Amodal Segmentation by Synthesizing Wholes},
    author={Ege Ozguroglu and Ruoshi Liu and D\'idac Sur\'is and Dian Chen and Achal Dave and Pavel Tokmakov and Carl Vondrick},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2024}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="viper-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/viper.gif" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>*,
                            <a href="https://sachit-menon.github.io/" target="_blank">Sachit Menon</a>*,
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">ViperGPT: Visual Inference via Python Execution for Reasoning</b></span>
                            <i>International Conference on Computer Vision (ICCV) - ORAL PRESENTATION</i>, 2023.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2023viper')">[BibTeX]</a>
                            <a href="https://arxiv.org/abs/2303.08128" target="_blank">[PDF]</a>
                            <a href="http://viper.cs.columbia.edu">[Website]</a>
                        </p>
                        <div id="bib_Suris2023viper" class="bibtex noshow">
                            <pre>@article{surismenon2023vipergpt,
    title={ViperGPT: Visual Inference via Python Execution for Reasoning},
    author={D\'idac Sur\'is and Sachit Menon and Carl Vondrick},
    journal={Proceedings of IEEE International Conference on Computer Vision (ICCV)},
    year={2023}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="flex-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/flex_scene.png" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <a href="https://purvaten.github.io/" target="_blank">Purva Tendulkar</a>,
                            <b>Dídac Surís</b>,
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">FLEX: Full-Body Grasping Without Full-Body Grasps</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2023.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('TendulkarFlex')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/2211.11903.pdf" target="_blank">[PDF]</a>
                            <a href="http://flex.cs.columbia.edu">[Website]</a>
                        </p>
                        <div id="bib_TendulkarFlex" class="bibtex noshow">
                            <pre>@inproceedings{tendulkar2022flex,
    title={FLEX: Full-Body Grasping Without Full-Body Grasps},
    author={Tendulkar, Purva and Sur\'is, D\'idac and Vondrick, Carl},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2023}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="trajectories-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/web_figure_trajectories.gif" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>,
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Representing Spatial Trajectories as Distributions</b></span>
                            <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2022.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2022trajectories')">[BibTeX]</a>
                            <a href="https://arxiv.org/abs/2210.01322" target="_blank">[PDF]</a>
                            <a href="http://trajectories.cs.columbia.edu">[Website]</a>
                            <a href="javascript:toggleVideo('Suris2022trajectories')">[5min Video Presentation]</a>
                            <div id="vid_Suris2022trajectories" class="video noshow">
                                <iframe src="https://www.youtube.com/embed/eXgHeD8UnTs" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                            </div>
                        </p>
                        <div id="bib_Suris2022trajectories" class="bibtex noshow">
                            <pre>@article{suris2022trajectories,
    title={Representing Spatial Trajectories as Distributions},
    author={Sur\'is, D\'idac and Vondrick, Carl},
    journal={Advances in Neural Information Processing Systems 35 (NeurIPS)},
    year={2022}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="music-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/musicforvideo.png" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>,
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>,
                            <a href="https://bryanrussell.org" target="_blank">Bryan Russell</a> and
                            <a href="https://www.justinsalamon.com" target="_blank">Justin Salamon</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">It's Time for Artistic Correspondence in Music and Video</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2022.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2022musicforvideo')">[BibTeX]</a>
                            <a href="https://musicforvideo.cs.columbia.edu/paper.pdf" target="_blank">[PDF]</a>
                            <a href="http://musicforvideo.cs.columbia.edu">[Website]</a>
                            <a href="javascript:toggleVideo('Suris2022musicforvideo')">[5min Video Presentation]</a>
                            <div id="vid_Suris2022musicforvideo" class="video noshow">
                                <iframe src="https://www.youtube.com/embed/-WfJveyO1dA" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                            </div>
                        </p>
                        <div id="bib_Suris2022musicforvideo" class="bibtex noshow">
                            <pre>@article{suris2022musicforvideo,
    title={It's Time for Artistic Correspondence in Music and Video},
    author={Sur\'is, D\'idac and Vondrick, Carl and Russell, Bryan and Salamon, Justin},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="globetrotter-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/globetrotter.png" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>,
                            <a href="https://dave.ml" target="_blank">Dave Epstein</a> and
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Globetrotter: Unsupervised Multilingual Translation from Visual Alignment</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR) - ORAL PRESENTATION</i>, 2022.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2022globetrotter')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/2012.04631.pdf" target="_blank">[PDF]</a>
                            <a href="https://github.com/cvlab-columbia/globetrotter">[Code and model]</a>
                            <a href="http://globetrotter.cs.columbia.edu">[Website]</a>
                            <a href="javascript:toggleVideo('Suris2020globetrotter')">[5min Video Presentation]</a>
                            <div id="vid_Suris2020globetrotter" class="video noshow">
                                <iframe src="https://www.youtube.com/embed/SuM8QMsu5LA" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                            </div>
                        </p>
                        <div id="bib_Suris2020globetrotter" class="bibtex noshow">
                            <pre>@article{suris2022globetrotter,
    title={Globetrotter: Connecting Languages by Connecting Images},
    author={Sur\'is, D\'idac and Epstein, Dave and Vondrick, Carl},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="occlusion-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/occlusion.png" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <a href="https://basile.be/" target="_blank">Basile Van Hoorick</a>,
                            <a href="https://purvaten.github.io/" target="_blank">Purva Tendulkar</a>,
                            <b>Dídac Surís</b>,
                            <a href="https://scholar.google.com/citations?user=_UJsz3AAAAAJ&hl=en" target="_blank">Dennis Park</a>,
                            <a href="https://scholar.google.com/citations?user=f3aij5UAAAAJ&hl=en" target="_blank">Simon Stent</a> and
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Revealing Occlusions with 4D Neural Fields</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR) - ORAL PRESENTATION</i>, 2022.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('vanhoorick2022revealing')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/2204.10916.pdf" target="_blank">[PDF]</a>
                            <a href="https://github.com/basilevh/occlusions-4d">[Code and models]</a>
                            <a href="https://occlusions.cs.columbia.edu/">[Website]</a>
                            <a href="javascript:toggleVideo('Vanhoorick2022')">[5min Video Presentation]</a>
                            <div id="vid_Vanhoorick2022" class="video noshow">
                                <iframe src="https://www.youtube.com/embed/Q2S-ogGjcHo" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                            </div>
                        </p>
                        <div id="bib_vanhoorick2022revealing" class="bibtex noshow">
                            <pre>@article{vanhoorick2022revealing,
    title={Revealing Occlusions with 4D Neural Fields},
    author={Van Hoorick, Basile and Tendulkar, Purva and Sur\'is, D\'idac and Park, Dennis and Stent, Simon and Vondrick, Carl},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="hyperfuture-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/highFive1.gif" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>*,
                            <a href="https://www.linkedin.com/in/ruoshi-liu-a5046aa0/" target="_blank">Ruoshi Liu*</a> and
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Learning the Predictability of the Future</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2020hyperfuture')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/2101.01600.pdf" target="_blank">[PDF]</a>
                            <a href="https://github.com/cvlab-columbia/hyperfuture">[Code and model]</a>
                            <a href="http://hyperfuture.cs.columbia.edu">[Website]</a>
                            <a href="https://www.engineering.columbia.edu/press-release/ai-learns-to-predict-human-behavior-from-videos">[Press release]</a>
                            [Video Presentations <a href="javascript:toggleVideo('MIThyper')">(1h)</a>
                            <a href="javascript:toggleVideo('BCNhyper')">(15min)</a> <a href="javascript:toggleVideo('CVPRvideo')">(5min)</a>]
                        </p>
                        <div id="bib_Suris2020hyperfuture" class="bibtex noshow">
                            <pre>@InProceedings{suris2021hyperfuture,
    title={Learning the Predictability of the Future},
    author={Sur\'is, D\'idac and Liu, Ruoshi and Vondrick, Carl},
    journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2021}
}</pre>
                        </div>
                        <div id="vid_MIThyper" class="video noshow">
                            <iframe src="https://www.youtube.com/embed/-Uy92jvT_90" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                        </div>
                        <div id="vid_CVPRvideo" class="video noshow">
                            <iframe src="https://www.youtube.com/embed/rjAsiHEC2yE" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                        </div>
                        <div id="vid_BCNhyper" class="video noshow">
                            <iframe src="https://www.youtube.com/embed/07gz8eQokUU?start=9735&end=10614" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="expert-ref">
                    <div class="post-thumb">
                        <img class="icons" src="https://surisdi.github.io/assets/images/meta-learning.png" hspace="30"/>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>*,
                            <a href="https://dave.ml" target="_blank">Dave Epstein</a>,
                            <a href="https://cs.illinois.edu/about/people/faculty/hengji" target="_blank">Heng Ji</a>,
                            <a href="https://www.ee.columbia.edu/~sfchang/" target="_blank">Shih-Fu Chang</a> and
                            <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">Carl Vondrick</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Learning to Learn Words from Visual Scenes</b></span>
                            <i>European Conference on Computer Vision (ECCV)</i>, 2020.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2020')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/1911.11237.pdf" target="_blank">[PDF]</a>
                            <a href="https://github.com/cvlab-columbia/expert">[Code and model]</a>
                            <a href="javascript:toggleVideo('Suris2020expert')">[Video Presentation]</a>
                            <a href="http://expert.cs.columbia.edu">[Website]</a>
                            <div id="vid_Suris2020expert" class="video noshow">
                                <iframe src="https://www.youtube.com/embed/jou4-qbOCrY" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                            </div>
                        </p>
                        <div id="bib_Suris2020" class="bibtex noshow">
                            <pre>@Article{Suris2020learning,
    author = {Dídac Surís and D. Epstein and H. Ji and S. Chang and C. Vondrick},
    title = {Learning to Learn Words from Visual Scenes},
    journal = {European Conference on Computer Vision (ECCV)},
    year = {2020}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="drawing-learning-ref">
                    <div class="post-thumb">
                        <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Suris_Learning_Words_by_Drawing_Images_CVPR_2019_paper.pdf">
                        <img class="icons" src="https://surisdi.github.io/assets/images/learning_draw-1.png" hspace="30"/></a>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>*,
                            <a href="http://people.csail.mit.edu/recasens/" target="_blank">Adrià Recasens*</a>,
                            <a href="https://people.csail.mit.edu/davidbau/home/" target="_blank">David Bau</a>,
                            <a href="http://people.csail.mit.edu/dharwath/" target="_blank">David Harwath</a>,
                            <a href="https://www.csail.mit.edu/person/jim-glass" target="_blank">James Glass</a> and
                            <a href="http://web.mit.edu/torralba/www/" target="_blank">Antonio Torralba</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Learning Words by Drawing Images</b></span>
                            <i>Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2019.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2019')">[BibTeX]</a>
                            <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Suris_Learning_Words_by_Drawing_Images_CVPR_2019_paper.pdf" target="_blank">[PDF]</a>
                            <a href="https://github.com/surisdi/learning-by-drawing">[Code]</a>
                            <a href="http://clevrgan.csail.mit.edu">[Website]</a>
                        </p>
                        <div id="bib_Suris2019" class="bibtex noshow">
                            <pre>@Article{Suris2019,
    author = {D. Sur\'is and A. Recasens and D. Bau and D. Harwath and J. Glass and A. Torralba},
    title = {Learning Words by Drawing Images},
    journal = {Conference on Computer Vision and Pattern Recognition (CVPR)},
    year = {2019}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container" id="eccv_harwath">
                    <div class="post-thumb"><a href="https://arxiv.org/abs/1804.01452">
                        <img class="icons" src="https://surisdi.github.io/assets/images/speech_audio2.png" hspace="30"/></a>
                    </div>
                    <div class="post-content">
                        <p>
                            <a href="http://people.csail.mit.edu/dharwath/" target="_blank">David Harwath</a>,
                            <a href="http://people.csail.mit.edu/recasens/" target="_blank">Adrià Recasens</a>,
                            <b>Dídac Surís</b>,
                            <a href="https://www.linkedin.com/in/galenchuang/" target="_blank">Galen Chuang</a>,
                            <a href="http://web.mit.edu/torralba/www/" target="_blank">Antonio Torralba</a> and
                            <a href="https://www.csail.mit.edu/person/jim-glass" target="_blank">James Glass</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input</b></span>
                            <i>European Conference on Computer Vision (ECCV)</i>, 2018 (ORAL PRESENTATION).
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Harwath2018')">[BibTeX]</a>
                            <a href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/David_Harwath_Jointly_Discovering_Visual_ECCV_2018_paper.pdf" target="_blank">[PDF]</a>
                            <a href="http://groups.csail.mit.edu/sls/downloads/placesaudio/" target="_blank">[Code and data]</a>
                            <a href="javascript:toggleVideo('Harwath2018')">[Video Presentation]</a>
                            <a href="http://news.mit.edu/machine-learning-image-object-recognition-0918" target="_blank">[MIT News]</a>
                        </p>
                        <div id="bib_Harwath2018" class="bibtex noshow">
                            <pre>@Article{Harwath2018,
    author = {D. Harwath and A. Recasens and D. Sur\'is and G. Chuang and A. Torralba and J. Glass},
    title = {Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input},
    journal = {European Conference on Computer Vision (ECCV)},
    year = {2018}
}</pre>
                        </div>
                        <div id="vid_Harwath2018" class="video noshow">
                            <iframe src="https://www.youtube.com/embed/fNm4fh2ub9c" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                        </div>
                    </div>
                </div>

                <div class="post-container">
                    <div class="post-thumb"><a href="https://arxiv.org/abs/1801.01423">
                        <img class="icons" src="https://surisdi.github.io/assets/images/hat2.png" hspace="30"/></a>
                    </div>
                    <div class="post-content">
                        <p>
                            <a href="http://joanserra.weebly.com" target="_blank">Joan Serrà</a>, <b>Dídac Surís</b>,
                            <a href="http://mariusmiron.com/" target="_blank">Marius Miron</a> and <a href="https://alexiskz.wordpress.com/" target="_blank">Alexandros Karatzoglou</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Overcoming catastrophic forgetting with hard attention to the task</b></span>
                            <i>International Conference on Machine Learning (ICML)</i>, 2018 (LONG TALK).
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Serra2018')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/1801.01423" target="_blank">[PDF]</a>
                            <a href="https://github.com/joansj/hat">[Code]</a>
                            <a href="javascript:toggleVideo('Serra2018')">[Video Presentation(21:20)]</a>
                            <a href="https://www.techworld.com/tech-innovation/what-is-catastrophic-forgetting-how-does-it-affect-ai-development-3687007/" target="_blank">[Tech World News]</a>
                        </p>
                        <div id="bib_Serra2018" class="bibtex noshow">
                            <pre>@Article{Serra2018,
    author = {J. Serr\`a and D. Sur\'is and M. Miron and A. Karatzoglou},
    title = {Overcoming catastrophic forgetting with hard attention to the task},
    journal = {International Conference on Machine Learning (ICML)},
    year = {2018}
}</pre>
                        </div>
                        <div id="vid_Serra2018" class="video noshow">
                            <iframe src="https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Ficml.imls%2Fvideos%2F432573817257139%2F&show_text=0&width=560" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true" class="video noshow"></iframe>
                        </div>
                    </div>
                </div>

                <div class="post-container">
                    <div class="post-thumb"><a href="https://arxiv.org/abs/1801.02200">
                        <img class="icons" src="https://surisdi.github.io/assets/images/crossmodal2.png" hspace="30"/></a>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>,
                            <a href="https://imatge.upc.edu/web/people/amanda-duarte" target="_blank">Amanda Duarte</a>,
                            <a href="https://imatge.upc.edu/web/people/amaia-salvador" target="_blank">Amaia Salvador</a>,
                            <a href="http://jorditorres.org/" target="_blank">Jordi Torres</a> and
                            <a href="https://imatge.upc.edu/web/people/xavier-giro" target="_blank">Xavier Giró-i-Nieto</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Cross-modal Embeddings for Video and Audio Retrieval</b></span>
                            <i>European Conference on Computer Vision Workshops (ECCV Workshops)</i>, 2018.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2018')">[BibTeX]</a>
                            <a href="https://arxiv.org/pdf/1801.02200.pdf" target="_blank">[PDF]</a>
                        </p>
                        <div id="bib_Suris2018" class="bibtex noshow">
                            <pre>@Article{Suris2018,
    author = {D. Sur\'is and A. Duarte and A. Salvador and J. Torres and X. Gir\'o-i-Nieto},
    title = {Cross-modal Embeddings for Video and Audio Retrieval},
    journal = {European Conference on Computer Vision Workshops (ECCV Workshops)},
    year = {2018}
}</pre>
                        </div>
                    </div>
                </div>

                <div class="post-container">
                    <div class="post-thumb"><a href="https://ieeexplore.ieee.org/document/7962637/">
                        <img class="icons" src="https://surisdi.github.io/assets/images/backhaul2.png" hspace="30"/></a>
                    </div>
                    <div class="post-content">
                        <p>
                            <b>Dídac Surís</b>, <a href="http://directori.upc.edu/directori/dadesPersona.jsp?id=1049032" target="_blank">Adrian Agustin</a> and <a href="http://directori.upc.edu/directori/dadesPersona.jsp?id=1002406" target="_blank">Josep Vidal</a>
                            <br class="spacing-before"><span class="title-line"><b class="paper-title">Delay minimization in dynamic and scalable multi-operator wireless backhauling</b></span>
                            <i>IEEE International Conference on Communications Workshops (ICC Workshops)</i>, 2017.
                            <br class="spacing" />
                            <a href="javascript:toggleBibtex('Suris2017')">[BibTeX]</a>
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7962637" target="_blank">[PDF]</a>
                        </p>
                        <div id="bib_Suris2017" class="bibtex noshow">
                            <pre>@Article{Suris2017,
    author = {D. Sur\'is and A. Agustin and J. Vidal},
    title = {Delay minimization in dynamic and scalable multi-operator wireless backhauling},
    journal = {IEEE International Conference on Communications Workshops (ICC Workshops)},
    year = {2017}
}</pre>
                        </div>
                    </div>
                </div>
            </section>
        </div>

        <!-- RESUME SECTION -->
        <div id="resume" class="tab-content">
            <section>
                <h2>Resume</h2>
                <div class="resume-highlight">
                    <a href="https://docs.google.com/uc?export=download&id=1pxFX51IHrjXo53luTTtb2cgOKF2aGIrF" target="_blank">Download Resume (PDF)</a>
                </div>

                <div class="resume-section">
                    <h3>Research Experience</h3>
                    <ul>
                        <li>Research Scientist at <a href="https://ai.meta.com">Meta Superintelligence Labs</a></li>
                        <li>PhD Student at <a href="https://www.cs.columbia.edu">Columbia University</a>, in Carl Vondrick's group - Microsoft PhD Fellow</li>
                        <li>Internship at Meta (FAIR) - Research on large language models for video understanding</li>
                        <li>Internship at Adobe Research - Research in the intersection of music and video</li>
                        <li>Research Assistant at <a href="https://vectorinstitute.ai">Vector Institute</a>, in Sanja Fidler's group</li>
                        <li>Visiting Student at <a href="https://www.csail.mit.edu">CSAIL-MIT</a>, at Antonio Torralba's lab</li>
                        <li>Internship at <a href="http://www.tid.es">Telefonica Research</a> - Developed a method to avoid catastrophic forgetting in neural networks</li>
                    </ul>
                </div>

                <div class="resume-section">
                    <h3>Awards & Fellowships</h3>
                    <ul>
                        <li>Microsoft PhD Fellow</li>
                        <li>"la Caixa" fellowship to carry out graduate studies in North America</li>
                        <li>Best academic record awards in both BSc and MSc</li>
                        <li>Excellence Master's degree Grants by the Catalunya-La Pedrera foundation</li>
                    </ul>
                </div>

                <div class="resume-section">
                    <h3>Education</h3>
                    <ul>
                        <li>PhD in Computer Science - Columbia University</li>
                        <li>MSc in Telecommunications - UPC BarcelonaTech</li>
                        <li>BSc in Telecommunications - UPC BarcelonaTech</li>
                    </ul>
                </div>
            </section>
        </div>
    </div>

    <script>
        // Toggle BibTeX display
        function toggleBibtex(articleid) {
            var bib = document.getElementById('bib_'+articleid);
            if (bib) {
                if(bib.className.indexOf('bibtex') != -1) {
                    bib.className.indexOf('noshow') == -1 ? bib.className = 'bibtex noshow' : bib.className = 'bibtex';
                }
            } else {
                return;
            }
        }

        // Toggle Video display
        function toggleVideo(articleid) {
            var vid = document.getElementById('vid_'+articleid);
            if (vid) {
                if(vid.className.indexOf('video') != -1) {
                    vid.className.indexOf('noshow') == -1 ? vid.className = 'video noshow' : vid.className = 'video';
                }
            } else {
                return;
            }
        }
    </script>
</body>
</html>
